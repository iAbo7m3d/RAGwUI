import streamlit as st
import traceback
from pinecone import Pinecone
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from typing import List

# --- Configuration via user input ---
st.sidebar.header("ğŸ”‘ Ø£Ø¯Ø®Ù„ Ù…ÙØ§ØªÙŠØ­ API")
OPENAI_API_KEY = st.sidebar.text_input("OpenAI API Key", type="password")
PINECONE_API_KEY = st.sidebar.text_input("Pinecone API Key", type="password")

if not OPENAI_API_KEY or not PINECONE_API_KEY:
    st.sidebar.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØ§ØªÙŠØ­ OpenAI Ùˆ Pinecone Ù„Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.")
    st.stop()

INDEX_NAME = "labor-law-v2"

# Initialize embedding model, Pinecone client, and OpenAI client
embedder = SentenceTransformer("intfloat/multilingual-e5-large", device="cpu")
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)
client = OpenAI(api_key=OPENAI_API_KEY)

# Session state for chat history
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Ù…Ø±Ø­Ø¨Ù‹Ø§! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙÙ‡Ù… Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŸ"}
    ]


def retrieve_context_simple(query: str, top_k: int = 10) -> List[str]:
    # 1) Encode the query
    q_vec = embedder.encode(query, normalize_embeddings=True).tolist()
    # 2) Retrieve top_k matches
    resp = index.query(vector=q_vec, top_k=top_k, include_metadata=True)
    matches = resp.get("matches", [])
    # 3) Extract content
    return [m["metadata"].get("content", "") for m in matches]


def generate_response_simple(query: str) -> str:
    
    chunks = retrieve_context_simple(query)
    if not chunks:
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ§Ø­Ø© Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„."
    context = "\n\n".join(chunks)
    messages = [
        {"role": "system", "content": (
            "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©. "
            " Ø£Ø¬Ø¨ Ø¨Ø¯Ù‚Ø© ÙˆØ¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©."
            "Ø§Ø°ÙƒØ± Ù†Øµ Ø§Ù„Ù…Ø§Ø¯Ø© ÙˆØ±Ù‚Ù…Ù‡Ø§ Ø§Ù„ØªÙŠ Ø§Ø³ØªÙ†Ø¯Øª Ø¹Ù„ÙŠÙ‡Ø§ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ø¬Ø§Ø¨ØªÙƒ "
            "Ø§Ø¬ØªÙ†Ø¨ Ø°ÙƒØ± Ø§Ù„Ù…ÙˆØ§Ø¯ ÙˆØ§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªÙŠ Ù„ÙŠØ³Øª Ù„Ù‡Ø§ Ø¹Ù„Ø§Ù‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„"
        )},
        {"role": "user", "content": f"Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\n{context}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {query}"}
    ]
    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=messages,
            temperature=0.2,
            max_tokens=2000
        )
        return response.choices[0].message.content.strip()
    except Exception:
        traceback.print_exc()
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."


def main():
    st.title("ğŸ¤– Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ø¢Ù„ÙŠ")

    with st.sidebar:
        st.header("ğŸ“š Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        st.markdown("""
        ### Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        1. **Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©**: Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ ÙÙŠ ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„.
        2. **Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ø­ÙˆØ§Ø±**: Ø§Ù„Ø£Ø¯Ø§Ø© ØªØªØ°ÙƒØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©ØŒ ÙˆÙŠÙ…ÙƒÙ†Ùƒ Ø·Ø±Ø­ Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ§Ø¨Ø¹Ø©.
        3. **Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©**: Ù‚Ù… Ø¨Ø§Ù„ØªÙ…Ø±ÙŠØ± Ù„Ù„Ø£Ø¹Ù„Ù‰ Ù„Ø±Ø¤ÙŠØ© ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©.
        """)
        if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
            st.session_state.messages = [
                {"role": "assistant", "content": "Ù…Ø±Ø­Ø¨Ù‹Ø§! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙÙ‡Ù… Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŸ"}
            ]
            st.rerun()

    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Handle user input
    if user_input := st.chat_input("Ù…Ø§ Ù‡Ùˆ Ø³Ø¤Ø§Ù„Ùƒ Ø­ÙˆÙ„ Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ØŸ"):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                reply = generate_response_simple(user_input)
                st.markdown(reply)
                st.session_state.messages.append({"role": "assistant", "content": reply})


if __name__ == "__main__":
    main()
